{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "sc = SparkContext('local', 'RDD_Practice')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "135a7805-d1df-4b13-bbd3-211705b7f129",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating an RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c9ac3304-f7e1-4c2c-9bc4-e82466892f3a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Two common methods:\n",
    "* textFile (input: text file) \n",
    "* parallelize (input: a list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "952bf4ef-45e0-4a22-af30-a590b9001fb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's create our first RDD using a csv of some public data\n",
    "crimes_rdd = sc.textFile(\"Chicago-Crimes-2018.csv\")\n",
    "#Creates a list of strings (one line = one element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "be4dbce9-d37a-49f1-bc32-4a943db3be29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# investigate the type of the variable we created\n",
    "print(type(crimes_rdd))\n",
    "print(crimes_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f2c4b9ed-79b0-4ca9-8797-d9ebbe9eb8d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# investigate the data in the RDD\n",
    "crimes_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "736d61b9-9c5e-431f-846f-cc9322916534",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's create another RDD using parallelize function\n",
    "simple_list = [\"This\", \"is\", \"a\", \"list\"]\n",
    "list_rdd = sc.parallelize(simple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a2b4ad94-9f8f-4d45-a021-131d297a101b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(type(list_rdd))\n",
    "print(list_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "497f3413-2002-48a9-a602-720d656bacef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list_rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "68852733-fb9a-45c2-b787-15f558c16178",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Operations\n",
    "2 types of operations:\n",
    "* Transformations\n",
    "    * Returns 1 or more RDDs\n",
    "    * Lazy - no immediate execution\n",
    "* Actions\n",
    "    * Returns non-RDD values\n",
    "    * Eager - triggers evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b70fd2ab-ccb7-4075-9bfa-c635286314b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bfe22018-b519-4fd0-9af0-f41eb48d559f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Map, flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0c30664e-8f5a-49e9-a529-9565e56f1643",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# you can use help to find some quick info on a function\n",
    "help(list_rdd.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7c05c467-af6b-44bf-ad4a-5f041e6d30d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "map_list_rdd = list_rdd.map(lambda x: (x, len(x)))\n",
    "map_list_rdd.take(4)\n",
    "\n",
    "# note: lambda functions are common in Spark RDDs. Read more in the link below, if unfamiliar with lambda:\n",
    "# https://www.w3schools.com/python/python_lambda.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fcff0779-be30-41f2-bbe0-d4ac86238492",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# it is possible to use regular functions as well. Useful for complex functions\n",
    "# but generally this is too wordy and needless complexity\n",
    "\n",
    "def give_length(x):\n",
    "  return (x, len(x))\n",
    "\n",
    "list_rdd.map(give_length).take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "705afa1c-d066-4fd4-8319-93ebeeb942fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# flatMap flattens the output to a single level list\n",
    "\n",
    "list_rdd.flatMap(lambda x: (x, len(x))).take(4) #.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5c20e726-c60e-45c3-a3a2-7c97de28cc01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#crimes_rdd.take(4) # Every row is a long string, hard to do data processing\n",
    "crimes_rdd.map(lambda x: x.split('\\t')).take(4) # Now we have some structure - list of lists, every sublist is a row with index responding to column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "00bc0b71-9cc3-4a58-ade8-188a19803a53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9a6e4b50-b79c-4731-a834-d4c7fbeccd69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list_rdd.filter(lambda x: len(x)>2).take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bcc2280e-771b-4118-bd4b-8c0f52cb76f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# you can start combining multiple transformations\n",
    "\n",
    "# note on notation: common to use (brackets) and every transformation/action on new line for improved readability\n",
    "\n",
    "(list_rdd\n",
    " .map(lambda x: (len(x), x))\n",
    " .filter(lambda x: x[0]>2).take(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bd501e69-7b71-44a8-9e2f-573c2b778e78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# find all crimes where there's been an arrest (column 9 = Arrest)\n",
    "(crimes_rdd\n",
    " .map(lambda x: x.split('\\t'))\n",
    " .filter(lambda x: x[8]==\"true\")\n",
    " .take(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "13664948-aab1-44f8-9ae3-23d885783771",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Union & intersection\n",
    "\n",
    "<img src= 'https://i.ytimg.com/vi/sdflTUW6gHo/maxresdefault.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a70e2b70-440a-47d8-b1fe-7600b82d9d6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's create some more RDDs. These are called pair RDDs, as they are key-value pairs\n",
    "\n",
    "first_rdd = sc.parallelize([\n",
    "  (1, \"Batman\"),\n",
    "  (2, \"Superman\"),\n",
    "  (3, \"Spiderman\")\n",
    "])\n",
    "\n",
    "second_rdd = sc.parallelize([\n",
    "  (3, \"Spiderman\"),\n",
    "  (4, \"Hulk\"),\n",
    "  (5, \"Peppa Pig\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a46d0a18-c8e0-4459-a3b8-c866e2be537d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(first_rdd\n",
    " .union(second_rdd)\n",
    " .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "04ffd7c5-235a-45b5-a511-876e9255b7e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(first_rdd\n",
    " .intersection(second_rdd)\n",
    " .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "46b5e795-a094-4c4d-b18a-bdda53188503",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0a918f42-df0e-420c-b425-81578535986d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# returns duplicate values for spiderman\n",
    "(first_rdd\n",
    " .union(second_rdd)\n",
    " .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7465ac06-0e18-4990-81ff-216dde944ad2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# returns distinct values\n",
    "(first_rdd\n",
    " .union(second_rdd)\n",
    " .distinct()\n",
    " .take(10) \n",
    ")\n",
    "# note: order not preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f093c13c-0463-4044-a5e1-d8e4f31ae4fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### ByKey operations\n",
    "* groupByKey\n",
    "* reduceByKey\n",
    "* sortByKey\n",
    "* aggregateByKey\n",
    "\n",
    "expect pair RDDs _(key, value)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "89f2a5fa-80bf-4284-acdc-8787f59745b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for i in first_rdd.union(second_rdd).groupByKey().take(10): # this is a list of tuples, second element is iterable\n",
    "  print(i[0], [j for j in i[1]])\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7105f365-4003-4c44-bf26-46b18f0846ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "GroupByKey vs ReduceByKey </br>\n",
    "<img src ='https://www.edureka.co/community/?qa=blob&qa_blobid=6565348686735863167'> </br>\n",
    "<img src ='https://www.edureka.co/community/?qa=blob&qa_blobid=8024890559746280233'>\n",
    "\n",
    "_source: https://www.edureka.co/community/11996/groupbykey-vs-reducebykey-in-apache-spark_\n",
    "\n",
    "reduceByKey is generally faster and preferred for grouping, compared to groupByKey\n",
    "\n",
    "reduce will perform calculations (eg aggregations) within partition, and provides smaller output\n",
    "\n",
    "Further info: https://stackoverflow.com/questions/24804619/how-does-spark-aggregate-function-aggregatebykey-work/24805905#24805905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2fbc9c33-2811-4f6f-bb63-bb172378bab7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# NB! aggregation must be commutative and associative (eg add, multiply). Average/st deviation not directly implementable\n",
    "\n",
    "(first_rdd\n",
    " .union(second_rdd)\n",
    " .reduceByKey(lambda x,y: (x, y))\n",
    " .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2dfaeb06-c2ea-42ec-938d-fd22a2cbe27d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(first_rdd\n",
    " .union(second_rdd)\n",
    " .map(lambda x: (x[1],x[0]))\n",
    " .reduceByKey(lambda x, y: x+y)\n",
    " .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "91078dd6-9633-4626-b633-c58e8079e42f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# sorting\n",
    "(first_rdd\n",
    " .union(second_rdd)\n",
    " .sortByKey(ascending=False)\n",
    " .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "29a2f75c-9301-41e9-8c22-93ce3d99e7a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# sorting previous distinct query\n",
    "(first_rdd\n",
    " .union(second_rdd)\n",
    " .distinct()\n",
    " .sortByKey()\n",
    " .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ed731526-258b-4cba-b0bb-cc8ac8ff7b56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# aggregate by key takes 3 inputs: first value, function within partition, function after partition combination\n",
    "(first_rdd\n",
    " .union(second_rdd)\n",
    " .aggregateByKey(\"\",lambda x,y:x+y,lambda x,y:x+\",\"+y)\n",
    " .take(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9c1682ad-8e0d-4740-ac5d-12b213662ce7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's create another RDD for further calculations\n",
    "third_rdd = sc.parallelize([\n",
    "  (10, 'Batman'),\n",
    "  (20, 'Superman'),\n",
    "  (30, 'Hulk'),\n",
    "  (40, 'Hulk')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e6318c5e-c056-4036-ac11-cdd9df1a7bb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# demonstration for calculating average\n",
    "(first_rdd\n",
    " .union(second_rdd)\n",
    " .union(third_rdd)\n",
    " .map(lambda x: (x[1],x[0]))\n",
    " .aggregateByKey((0,0)\n",
    "                 ,lambda x,y:(x[0]+y, x[1]+1)\n",
    "                 ,lambda x,y:(x[0]+y[0],x[1]+y[1])\n",
    "                )\n",
    " #.mapValues(lambda x: x[0]/x[1]) # mapValues works on pair RDDs, only mapping the values part of the key-values\n",
    " .take(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a16a013f-1076-455a-9f21-d8b91ed0cc66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# some general math functions based on reduce\n",
    "(first_rdd\n",
    " .union(second_rdd)\n",
    " .union(third_rdd)\n",
    " .map(lambda x: (x[1],x[0]))\n",
    "# .reduceByKey(lambda x,y: x+y) # sum\n",
    "# .reduceByKey(min) \n",
    "# .reduceByKey(max)\n",
    " .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e314646b-d929-41fc-b3f0-7e17a65a6f80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# reduceByKey is not intuitively suited for getting the mean (or std deviation, etc). See above for aggregateByKey solution\n",
    "(first_rdd\n",
    " .union(second_rdd)\n",
    " .union(third_rdd)\n",
    " .map(lambda x: (x[1],x[0]))\n",
    " .mapValues(lambda x: (x, 1))\n",
    " .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1]))\n",
    " .map(lambda x: (x[0], x[1][0]/x[1][1]))\n",
    " .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0dc6bbe4-d65a-4475-9f57-249847b47b8e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "60db4ea3-d77e-409d-a8f0-5e0849fb8463",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# join is by key, returns (key, (value A, value B)\n",
    "(first_rdd\n",
    ".join(second_rdd)\n",
    "#.fullOuterJoin(second_rdd)\n",
    "#.leftOuterJoin(second_rdd)\n",
    ".take(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7b25d23c-0f06-45c1-8de0-3d6fd56111f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(first_rdd\n",
    " .map(lambda x: (x[1],x[0]))\n",
    " .join(third_rdd.map(lambda x: (x[1],x[0])))\n",
    " .take(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cff9826b-6315-4fdd-8235-4a02e8bb2207",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "563adffd-84c4-461c-b378-d01ded59f415",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# displaying contents\n",
    "#first_rdd.collect() # NB takes full dataset into driver memory\n",
    "#first_rdd.take(1) # returns a list\n",
    "#first_rdd.first() # returns first element from RDD - NB type is not same as for take(1)\n",
    "#first_rdd.top(1) # returns n items starting from \"the top\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5c371e98-d317-4164-86b6-6129c9a39c9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# count of items/rows in RDD\n",
    "first_rdd.count()\n",
    "#crimes_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e5b7128d-2c73-4907-8bd2-17ee4558f962",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# reduce - calculate a result for whole RDD \n",
    "(first_rdd\n",
    " #.map(lambda x: x[0])\n",
    " .reduce(lambda x,y: x+y) #sum\n",
    " #.reduce(max)\n",
    " #.reduce(min)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "868054ee-ef8a-470d-b17d-9349d25f99c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# simple sum/mean/max/min functions\n",
    "\n",
    "#first_rdd.map(lambda x: x[0]).sum()\n",
    "#first_rdd.map(lambda x: x[0]).mean()\n",
    "#first_rdd.map(lambda x: x[0]).min()\n",
    "#first_rdd.map(lambda x: x[0]).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ddddc054-4ddf-46bd-93d7-69cb5901ffca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Example\n",
    "Let's use sample data from https://jsonplaceholder.typicode.com/\n",
    "\n",
    "We will try to see what is the **average length** of **post title**, per **user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a53c0edf-f0cf-4893-ab03-b8e20f882925",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "users_path = \"https://jsonplaceholder.typicode.com/users\"\n",
    "users_resp = requests.get(users_path)\n",
    "\n",
    "posts_path = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "posts_resp = requests.get(posts_path)\n",
    "\n",
    "users_rdd = sc.parallelize(users_resp.json())\n",
    "posts_rdd = sc.parallelize(posts_resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f548128a-5bb7-47be-9d2b-e5b0c3fdc1a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "users_rdd.take(3)\n",
    "# we will be interested in id and name fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4ea4aa65-91f9-41a1-b1d5-05f2016f974d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "posts_rdd.take(3)\n",
    "# userId matches id from users_rdd. We are also interested in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "422d5462-9e9e-4867-97ff-c25f03f9cd5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# both RDDs are a list of dictionaries, so we can use Python dictionary methods for accessing the fields we are interested in\n",
    "(users_rdd\n",
    " .map(lambda x: (x[\"id\"], x[\"name\"]))\n",
    " .take(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f4308ade-37fb-48ef-b8cb-9a35782d9a2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(posts_rdd\n",
    " .map(lambda x: (x[\"userId\"], x[\"title\"])) # we do not need the actual title, can take len()\n",
    " .take(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "acd6c045-b029-4836-b933-506495c2e4e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# let's join these two RDDs\n",
    "(users_rdd\n",
    " .map(lambda x: (x[\"id\"], x[\"name\"]))\n",
    " .join(posts_rdd\n",
    "       .map(lambda x: (x[\"userId\"], len(x[\"title\"]))))\n",
    " .take(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "263d8152-db36-46f7-9771-8dde65849d92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# we can now finalize our query\n",
    "(users_rdd\n",
    " .map(lambda x: (x[\"id\"], x[\"name\"]))\n",
    " .join(posts_rdd\n",
    "       .map(lambda x: (x[\"userId\"], len(x[\"title\"]))))\n",
    " .map(lambda x: (x[1][0],x[1][1]))\n",
    " .aggregateByKey((0,0)\n",
    "                 ,lambda x,y:(x[0]+y, x[1]+1)\n",
    "                 ,lambda x,y:(x[0]+y[0],x[1]+y[1])\n",
    "                )\n",
    " .mapValues(lambda x: x[0]/x[1])\n",
    " .sortBy(lambda x: x[1], ascending=False)\n",
    " .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a32cb86c-ba37-443b-8291-069908490c9c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Additional reading material\n",
    "\n",
    "Official documentation:</br>\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html </br>\n",
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.html\n",
    "\n",
    "RDDs pros and cons:</br>\n",
    "https://www.databricks.com/glossary/what-is-rdd </br>\n",
    "https://dzone.com/articles/apache-spark-3-reasons-why-you-should-not-use-rdds </br>\n",
    "https://towardsdatascience.com/a-modern-guide-to-spark-rdds-725cd7c14059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cf9c8f4b-a7f6-4110-9502-c12346329af7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Task 1\n",
    "\n",
    "Using the Chicago crimes dataset from above, create:\n",
    "1. an RDD holding a distinct list of the column \"Primary type\" (30 rows total including heading)\n",
    "2. an RDD holding the same distinct list as RDD 1, but including a count of each \"Primary type\" in the dataset, eg: ('HOMICIDE', 48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2163f184-de1f-43de-871d-1352eb9cbfdf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# first RDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d00cf6ad-9c72-41a7-a5d2-cd48a174515d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# second RDD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d59e2b0e-4784-4a84-b84a-9d713150ab7a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Task 2\n",
    "\n",
    "Using the jsonplaceholder data, create an RDD that would return username and proportion (decimal percentage) of todos done.\n",
    "\n",
    "Endpoints:\n",
    "* https://jsonplaceholder.typicode.com/users\n",
    "* https://jsonplaceholder.typicode.com/todos\n",
    "\n",
    "Expected output is a sorted RDD, descending by proportion.</br>\n",
    "Example take(3):</br>\n",
    "[('Moriah.Stanton', 0.6),</br>\n",
    " ('Kamren', 0.6),</br>\n",
    " ('Maxime_Nienow', 0.55)]</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a237db8e-7cd1-4f42-8629-551de033661e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# RDD\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "Practice session - RDD",
   "notebookOrigID": 2603459996185817,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
